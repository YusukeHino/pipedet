# Data situation is as follows:
# we have folders:
"""
data/images/0000_0.jpg (8376 images with 640x640x3 size)
data/saliency/0000_0.jpg (8376 images with 640x640x3 size)
data/crops.../0000_0_0.jpg (25128 images with 224x224x3 size)

Where we have 3 sets of numbers delineated by underscore.

first 0000 - corresponds to unique route segments, they all have same score and shouldn't be in the same training and validation set
second _0 - corresponds to various positioning on the street, where we "stood" and "looked"
third _0 - this applies for crops, we generated k smaller crops

1 image <=> 1 saliency generated by [1] <=> k crops
(ps: k was initially 3)

[1] = https://github.com/imatge-upc/saliency-salgan-2017/

"""

import numpy as np
import os
from helpers import path_exists

PATH = os.path.dirname(os.path.realpath(__file__)) + "/"

DATA_FOLDER_PATH = "/home/vruzicka/storage_pylon2/data/5556x_croppedTo_640x608_with_labels_saliencies_and_crops/"

def split_one_array(arr,validation_split=0.2, force_split_by_ids = True):
    split_at = int(len(arr) * (1 - validation_split))

    if force_split_by_ids:
        k = 0
        while arr[split_at+k][1] == arr[split_at][1]:
            k += 1
        split_at += k

    arr_train = arr[0:split_at]
    arr_val = arr[split_at:]

    return arr_train,arr_val

def load_dictionaries(include_osm=False):
    filename = PATH+"id_to_score.npy"
    if include_osm:
        filename = PATH+"id_to_score_and_osm.npy"

    if path_exists(DATA_FOLDER_PATH):
        filename = DATA_FOLDER_PATH + "id_to_score.npy"
        if include_osm:
            filename = DATA_FOLDER_PATH + "id_to_score_and_osm.npy"

    dictionary = np.load(filename).item()
    return dictionary

def get_data_from_folder(folder, include_osm=False):
    # get array of [[path,score,(osm)], ...]
    data = []
    dictionary = load_dictionaries(include_osm)

    if path_exists(DATA_FOLDER_PATH):
        files = os.listdir(DATA_FOLDER_PATH + folder)
    else:
        files = os.listdir(PATH+folder)

    files.sort()
    for i in range(len(files)):
    #for i in range(5):
        file = files[i]
        if file.endswith(".jpg"):
            path = PATH+os.path.join(folder, file)
            underscores = file.split("_")
            id = -1
            if len(underscores) == 2:
                id = file[0:-4]
            elif len(underscores) == 3:
                id = underscores[0]+"_"+underscores[1]
            label = dictionary[id]

            data.append( [path, id] + label )
    return data

def default_load(folder="crops_50proc_3clusters",force_split_by_ids=True):
    data = get_data_from_folder(folder)

    data_train, data_val = split_one_array(data,force_split_by_ids=force_split_by_ids)

    return data_train, data_val

def filenames_to_data(filenames, target_size=None):
    from keras.preprocessing.image import load_img, img_to_array

    imgs_arr = []
    for img_path in filenames:

        pil_img = load_img(img_path, target_size=target_size)
        arr = img_to_array(pil_img, 'channels_last')
        imgs_arr.append(arr)

    return np.array(imgs_arr)
